{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data from Spotify API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims at dowloading and storing all the required data for our analysis. As a reminder, the goal of this project is to analyse my Spotify tracks audio features to discover if I have a specific audio profile I like ( for example high energy, music you can groove too) or if, as I like to believe, I have various taste in audio profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import pandas as pd\n",
    "import time \n",
    "import numpy as np\n",
    "import os, pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User credentials and authentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading from csv that contains client id and client secret\n",
    "spotify_client_info = pd.read_csv('/Users/admin/Documents/spotify_client_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = spotify_client_info.iloc[0,0]\n",
    "client_secret = spotify_client_info.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spotipy.SpotifyOAuth\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(\n",
    "        client_id = spotify_client_info.iloc[0,0],\n",
    "        client_secret = spotify_client_info.iloc[0,1],\n",
    "        redirect_uri='http://localhost:8888/callback',\n",
    "        scope=\"user-library-read\"\n",
    "    ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track IDs collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I need to collect all my track IDs and gather them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrackIDs(user, playlist_id):\n",
    "    ids = []\n",
    "    playlist = sp.user_playlist(user, playlist_id)\n",
    "    for item in playlist['tracks']['items']:\n",
    "        track = item['track']\n",
    "        ids.append(track['id'])\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sp.current_user_saved_tracks(50)\n",
    "results['items'][0]['track']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "\n",
    "# Get current user's saved tracks\n",
    "results = sp.current_user_saved_tracks(limit=50)  # Adjust the limit if needed\n",
    "while results:\n",
    "    for idx, item in enumerate(results['items']):\n",
    "        track = item['track']\n",
    "        ids.append(track['id'])\n",
    "\n",
    "# Check if there are more tracks to retrieve\n",
    "    if results['next']:\n",
    "        results = sp.next(results)\n",
    "    else:\n",
    "        results = None\n",
    "\n",
    "ids\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the IDs list into a pkl file for easier and quicker access\n",
    "\n",
    "with open('spotify_tracks_ids.pkl', 'wb') as e:\n",
    "    pickle.dump(ids, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio features collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the ids from the file\n",
    "with open('spotify_tracks_ids.pkl', 'rb') as f:\n",
    "    ids = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5984 songs to loop from. I then chose to loop through batches of 100 songs to not exceed Spotify's rate limit. I am collecting for each song:\n",
    "- meta date (artist, song, name, release date and popularity)\n",
    "- audio features (acousticness, danceability, energy, instrumentalness, liveness, loudness, speechiness, tempo, valence, time_signature, key, mode, uri) https://developer.spotify.com/documentation/web-api/reference/get-audio-features\n",
    "\n",
    "All this information is grouped in a dataframe that will be exported to a pkl file for further analysis later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from spotipy.exceptions import SpotifyException\n",
    "\n",
    "def exponential_backoff_retry(func, *args, max_retries=3, base_delay=1, **kwargs):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except SpotifyException as e:\n",
    "            if e.http_status == 429:\n",
    "                print(f\"Rate limited. Retrying in {base_delay * 2 ** attempt} seconds.\")\n",
    "                time.sleep(base_delay * 2 ** attempt)\n",
    "            else:\n",
    "                raise e\n",
    "    print(\"Max retries exceeded. Unable to fetch track features.\")\n",
    "    return None\n",
    "\n",
    "def get_user_saved_track_features(sp, ids, start_track_id=0, batch_size=100):\n",
    "    all_tracks = []\n",
    "    total_tracks = len(ids)\n",
    "    \n",
    "    while start_track_id < total_tracks:\n",
    "        end_track_id = min(start_track_id + 1000, total_tracks)\n",
    "        tracks_f = []\n",
    "        tracks_m = []\n",
    "        \n",
    "        # Iterate through each batch of track IDs\n",
    "        batches = [ids[i:i+batch_size] for i in range(start_track_id, end_track_id, batch_size)]\n",
    "        for batch in batches:\n",
    "            for track_id in batch:\n",
    "                meta = exponential_backoff_retry(sp.track, track_id)\n",
    "                if meta is None:\n",
    "                    continue\n",
    "                name = meta['name']\n",
    "                album = meta['album']['name']\n",
    "                artist = meta['album']['artists'][0]['name']\n",
    "                release_date = meta['album']['release_date']\n",
    "                length = meta['duration_ms']\n",
    "                popularity = meta['popularity']\n",
    "                tracks_m.append([name, album, artist, release_date, length, popularity])\n",
    "                print(f\"Processed meta for track ID {track_id}\")\n",
    "            \n",
    "            batch_features = exponential_backoff_retry(sp.audio_features, batch)\n",
    "\n",
    "            if batch_features:\n",
    "                for features in batch_features:\n",
    "                    print(features)\n",
    "                    if features is not None and any(value is not None for value in features.values()):\n",
    "                        acousticness = features['acousticness']\n",
    "                        danceability = features['danceability']\n",
    "                        energy = features['energy']\n",
    "                        instrumentalness = features['instrumentalness']\n",
    "                        liveness = features['liveness']\n",
    "                        loudness = features['loudness']\n",
    "                        speechiness = features['speechiness']\n",
    "                        tempo = features['tempo']\n",
    "                        valence = features['valence']\n",
    "                        time_signature = features['time_signature']\n",
    "                        key = features['key']\n",
    "                        mode = features['mode']\n",
    "                        uri = features['uri']\n",
    "\n",
    "                        tracks_f.append([acousticness, danceability, energy, instrumentalness,\n",
    "                                       liveness, loudness, speechiness, tempo, valence,\n",
    "                                       time_signature, key, mode, uri])\n",
    "                        print(f\"Processed track ID {track_id}, {features['uri']}\")\n",
    "                    else:\n",
    "                        print(f\"Skipping track ID {track_id} because at least one feature value is None\")\n",
    "\n",
    "                    time.sleep(1)  # Sleep for 1 second per song\n",
    "            elif batch_features is None:\n",
    "                print(f\"Skipping batch due to error\")\n",
    "\n",
    "            time.sleep(1) # Sleep for 1 second per batch to avoid rate limiting\n",
    "        \n",
    "        batch_results = [meta_data + track_feature for meta_data, track_feature in zip(tracks_m, tracks_f)]\n",
    "        all_tracks.extend(batch_results)\n",
    "\n",
    "        start_track_id = end_track_id  # Update start_track_id to the next batch\n",
    "\n",
    "    return all_tracks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_track_features = get_user_saved_track_features(sp, ids, start_track_id=0, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('spotify_alltracks.pkl', 'wb') as f:\n",
    "    pickle.dump(all_track_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('spotify_alltracks.pkl', 'rb') as j:\n",
    "    all_track_features = pickle.load(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while None in all_track_features:\n",
    "    all_track_features.remove(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    df = pd.DataFrame(all_track_features, columns=['name', 'album', 'artist', 'release_date',\n",
    "                                       'length', 'popularity', 'acousticness', 'danceability',\n",
    "                                       'energy', 'instrumentalness', 'liveness', 'loudness',\n",
    "                                       'speechiness', 'tempo', 'valence', 'time_signature',\n",
    "                                       'key', 'mode', 'uri'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('spotify_df.pkl', 'wb') as l:\n",
    "    pickle.dump(df, l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
